#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çš„å”¤é†’è¯æ£€æµ‹æµ‹è¯•è„šæœ¬
ä¸“æ³¨äºæ£€æµ‹å”¤é†’è¯"å°æ™º"
"""

import sys
import os
import logging
import pyaudio
import vosk
import json
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class SimpleWakeWordDetector:
    """ç®€å•çš„å”¤é†’è¯æ£€æµ‹å™¨"""

    def __init__(self, model_path, wake_word="å°å…‰"):
        """åˆå§‹åŒ–æ£€æµ‹å™¨"""
        self.wake_word = wake_word
        self.chunk_size = 8000  # 400msçš„éŸ³é¢‘

        # åˆå§‹åŒ–PyAudio
        self.pa = pyaudio.PyAudio()

        # æŸ¥æ‰¾éº¦å…‹é£è®¾å¤‡å¹¶æ£€æµ‹æ”¯æŒçš„é‡‡æ ·ç‡
        self.mic_device = None
        self.sample_rate = None

        for i in range(self.pa.get_device_count()):
            dev_info = self.pa.get_device_info_by_index(i)
            if dev_info["maxInputChannels"] > 0:
                self.mic_device = i

                # å°è¯•è·å–è®¾å¤‡æ”¯æŒçš„é‡‡æ ·ç‡
                # å…ˆå°è¯•å¸¸ç”¨çš„é‡‡æ ·ç‡
                supported_rates = [16000, 44100, 48000, 8000, 22050]
                for rate in supported_rates:
                    try:
                        # å°è¯•æ‰“å¼€æµæ¥æ£€æµ‹é‡‡æ ·ç‡æ˜¯å¦æ”¯æŒ
                        stream = self.pa.open(
                            rate=rate,
                            channels=1,
                            format=pyaudio.paInt16,
                            input=True,
                            input_device_index=self.mic_device,
                            frames_per_buffer=1024,
                        )
                        stream.close()
                        self.sample_rate = rate
                        logger.info(f"éº¦å…‹é£æ”¯æŒé‡‡æ ·ç‡: {rate}Hz")
                        break
                    except:
                        continue

                if self.sample_rate is None:
                    # å¦‚æœéƒ½ä¸æ”¯æŒï¼Œä½¿ç”¨è®¾å¤‡é»˜è®¤é‡‡æ ·ç‡
                    self.sample_rate = int(dev_info["defaultSampleRate"])
                    logger.warning(
                        f"æ— æ³•æ£€æµ‹æ”¯æŒçš„é‡‡æ ·ç‡ï¼Œä½¿ç”¨é»˜è®¤é‡‡æ ·ç‡: {self.sample_rate}Hz"
                    )
                break

        if self.mic_device is None:
            logger.error("æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡")
            sys.exit(1)

        # åˆå§‹åŒ–Voskæ¨¡å‹å’Œè¯†åˆ«å™¨
        logger.info(f"åŠ è½½Voskæ¨¡å‹: {model_path}")
        self.model = vosk.Model(model_path)
        self.recognizer = vosk.KaldiRecognizer(self.model, self.sample_rate)

        logger.info(f"ä½¿ç”¨éº¦å…‹é£: #{self.mic_device}")
        logger.info(f"ä½¿ç”¨é‡‡æ ·ç‡: {self.sample_rate}Hz")
        logger.info(f"âœ… å”¤é†’è¯æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆï¼Œå”¤é†’è¯: '{self.wake_word}'")

    def start_listening(self):
        """å¼€å§‹ç›‘å¬éº¦å…‹é£"""
        logger.info("ğŸ¤ å¼€å§‹ç›‘å¬éº¦å…‹é£ï¼Œè¯´'å°å…‰'æ¥æµ‹è¯•å”¤é†’...")
        logger.info("æŒ‰ Ctrl+C åœæ­¢")

        # æ‰“å¼€éŸ³é¢‘æµ
        stream = self.pa.open(
            rate=self.sample_rate,
            channels=1,
            format=pyaudio.paInt16,
            input=True,
            input_device_index=self.mic_device,
            frames_per_buffer=self.chunk_size,
        )

        try:
            while True:
                # è¯»å–éŸ³é¢‘æ•°æ®
                data = stream.read(self.chunk_size, exception_on_overflow=False)

                # å‘é€éŸ³é¢‘æ•°æ®ç»™è¯†åˆ«å™¨
                if self.recognizer.AcceptWaveform(data):
                    # è·å–è¯†åˆ«ç»“æœ
                    result = json.loads(self.recognizer.Result())
                    print(result)
                    text = result.get("text", "").strip()

                    if text:
                        logger.info(f"è¯†åˆ«åˆ°: '{text}'")

                        # æ£€æŸ¥å”¤é†’è¯
                        if self.wake_word in text:
                            logger.info("âœ… å”¤é†’æˆåŠŸ!")
                            # break
                else:
                    # è·å–éƒ¨åˆ†ç»“æœ
                    partial = json.loads(self.recognizer.PartialResult())
                    partial_text = partial.get("partial", "").strip()
                    if partial_text:
                        # åœ¨åŒä¸€è¡Œæ˜¾ç¤ºéƒ¨åˆ†ç»“æœ
                        sys.stdout.write(f"\ræ­£åœ¨å¬: {partial_text}")
                        sys.stdout.flush()

                        # æ£€æŸ¥å”¤é†’è¯
                        if self.wake_word in partial_text:
                            logger.info("âœ… å”¤é†’æˆåŠŸ!")
                            # break

        except KeyboardInterrupt:
            logger.info("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­")
        finally:
            # å…³é—­éŸ³é¢‘æµ
            stream.stop_stream()
            stream.close()
            self.pa.terminate()
            logger.info("âœ… éŸ³é¢‘æµå·²å…³é—­")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("Vosk å”¤é†’è¯æ£€æµ‹ç®€å•æµ‹è¯•")

    # è®¾ç½®æ¨¡å‹è·¯å¾„
    model_path = "/root/vosk-model-small-cn-0.22"

    # åˆ›å»ºæ£€æµ‹å™¨
    detector = SimpleWakeWordDetector(model_path, wake_word="å°å…‰")

    # å¼€å§‹ç›‘å¬
    detector.start_listening()


if __name__ == "__main__":
    main()
